{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_embedding, parse_tup, cos_sim, cos_dist\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SquaredCircle</th>\n",
       "      <td>0.134779</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>-0.011876</td>\n",
       "      <td>-0.066840</td>\n",
       "      <td>0.020694</td>\n",
       "      <td>-0.055040</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>-0.082625</td>\n",
       "      <td>0.124690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061495</td>\n",
       "      <td>-0.183028</td>\n",
       "      <td>-0.099551</td>\n",
       "      <td>0.031485</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>0.143292</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>-0.008464</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>-0.172806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>0.135559</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>-0.037187</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>-0.006085</td>\n",
       "      <td>-0.017524</td>\n",
       "      <td>0.040978</td>\n",
       "      <td>-0.054059</td>\n",
       "      <td>0.069235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039066</td>\n",
       "      <td>-0.043172</td>\n",
       "      <td>-0.106157</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>-0.045787</td>\n",
       "      <td>0.063289</td>\n",
       "      <td>0.057239</td>\n",
       "      <td>-0.198356</td>\n",
       "      <td>0.061649</td>\n",
       "      <td>-0.023330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>-0.042422</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>-0.165820</td>\n",
       "      <td>0.046046</td>\n",
       "      <td>-0.080393</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.044797</td>\n",
       "      <td>0.094564</td>\n",
       "      <td>-0.090970</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>-0.087685</td>\n",
       "      <td>-0.129094</td>\n",
       "      <td>0.110916</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>-0.121198</td>\n",
       "      <td>0.155587</td>\n",
       "      <td>-0.057969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memes</th>\n",
       "      <td>0.002449</td>\n",
       "      <td>-0.014680</td>\n",
       "      <td>-0.031889</td>\n",
       "      <td>-0.051864</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>-0.055175</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>-0.135631</td>\n",
       "      <td>0.106458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>-0.042757</td>\n",
       "      <td>-0.033878</td>\n",
       "      <td>0.041545</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>0.076116</td>\n",
       "      <td>0.036539</td>\n",
       "      <td>-0.102034</td>\n",
       "      <td>0.054330</td>\n",
       "      <td>-0.073219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teenagers</th>\n",
       "      <td>0.026058</td>\n",
       "      <td>0.069684</td>\n",
       "      <td>0.024581</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>-0.029134</td>\n",
       "      <td>0.076384</td>\n",
       "      <td>0.078542</td>\n",
       "      <td>0.052331</td>\n",
       "      <td>-0.106552</td>\n",
       "      <td>0.096511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013686</td>\n",
       "      <td>-0.014345</td>\n",
       "      <td>-0.004146</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>0.085962</td>\n",
       "      <td>0.030374</td>\n",
       "      <td>-0.028468</td>\n",
       "      <td>0.069988</td>\n",
       "      <td>-0.039540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NRV</th>\n",
       "      <td>0.122154</td>\n",
       "      <td>0.130032</td>\n",
       "      <td>-0.243602</td>\n",
       "      <td>-0.032611</td>\n",
       "      <td>-0.038153</td>\n",
       "      <td>-0.014279</td>\n",
       "      <td>-0.065262</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>-0.099809</td>\n",
       "      <td>-0.018441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054521</td>\n",
       "      <td>-0.062958</td>\n",
       "      <td>-0.112747</td>\n",
       "      <td>0.098669</td>\n",
       "      <td>-0.049754</td>\n",
       "      <td>-0.015509</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>-0.216936</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>-0.123790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UTT</th>\n",
       "      <td>0.135902</td>\n",
       "      <td>0.057751</td>\n",
       "      <td>-0.200740</td>\n",
       "      <td>-0.035059</td>\n",
       "      <td>-0.005987</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.083139</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>-0.119045</td>\n",
       "      <td>0.125617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019219</td>\n",
       "      <td>-0.092823</td>\n",
       "      <td>-0.096780</td>\n",
       "      <td>0.095344</td>\n",
       "      <td>-0.114785</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>0.075017</td>\n",
       "      <td>-0.151421</td>\n",
       "      <td>0.048709</td>\n",
       "      <td>-0.065192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMU</th>\n",
       "      <td>0.119556</td>\n",
       "      <td>0.049138</td>\n",
       "      <td>-0.134668</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.023105</td>\n",
       "      <td>-0.025217</td>\n",
       "      <td>-0.026836</td>\n",
       "      <td>-0.026815</td>\n",
       "      <td>-0.198236</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075906</td>\n",
       "      <td>-0.067976</td>\n",
       "      <td>-0.035603</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>-0.084691</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>-0.040373</td>\n",
       "      <td>-0.134642</td>\n",
       "      <td>0.068508</td>\n",
       "      <td>-0.132696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houghton</th>\n",
       "      <td>0.065995</td>\n",
       "      <td>0.083532</td>\n",
       "      <td>-0.195394</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>0.061049</td>\n",
       "      <td>-0.019786</td>\n",
       "      <td>0.072973</td>\n",
       "      <td>-0.017989</td>\n",
       "      <td>-0.196128</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004768</td>\n",
       "      <td>-0.076079</td>\n",
       "      <td>-0.103230</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>-0.111134</td>\n",
       "      <td>0.028949</td>\n",
       "      <td>-0.011122</td>\n",
       "      <td>-0.188779</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>-0.115659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universityofredlands</th>\n",
       "      <td>0.179449</td>\n",
       "      <td>0.083221</td>\n",
       "      <td>-0.167956</td>\n",
       "      <td>-0.024700</td>\n",
       "      <td>0.049997</td>\n",
       "      <td>-0.046135</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>-0.078710</td>\n",
       "      <td>-0.128699</td>\n",
       "      <td>0.092061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024964</td>\n",
       "      <td>-0.054390</td>\n",
       "      <td>-0.168895</td>\n",
       "      <td>0.087481</td>\n",
       "      <td>-0.119883</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.023883</td>\n",
       "      <td>-0.181816</td>\n",
       "      <td>0.064438</td>\n",
       "      <td>-0.048578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10541 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           1         2         3         4         5    \\\n",
       "subreddit                                                                \n",
       "SquaredCircle         0.134779  0.043821 -0.011876 -0.066840  0.020694   \n",
       "AskReddit             0.135559  0.008985 -0.037187  0.000455  0.022365   \n",
       "politics             -0.042422  0.024062 -0.165820  0.046046 -0.080393   \n",
       "memes                 0.002449 -0.014680 -0.031889 -0.051864  0.044783   \n",
       "teenagers             0.026058  0.069684  0.024581  0.009624 -0.029134   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "NRV                   0.122154  0.130032 -0.243602 -0.032611 -0.038153   \n",
       "UTT                   0.135902  0.057751 -0.200740 -0.035059 -0.005987   \n",
       "MMU                   0.119556  0.049138 -0.134668  0.009505  0.023105   \n",
       "houghton              0.065995  0.083532 -0.195394  0.019086  0.061049   \n",
       "universityofredlands  0.179449  0.083221 -0.167956 -0.024700  0.049997   \n",
       "\n",
       "                           6         7         8         9         10   ...  \\\n",
       "subreddit                                                               ...   \n",
       "SquaredCircle        -0.055040  0.017334  0.004694 -0.082625  0.124690  ...   \n",
       "AskReddit            -0.006085 -0.017524  0.040978 -0.054059  0.069235  ...   \n",
       "politics              0.024717  0.044797  0.094564 -0.090970  0.013700  ...   \n",
       "memes                -0.055175  0.063965  0.009760 -0.135631  0.106458  ...   \n",
       "teenagers             0.076384  0.078542  0.052331 -0.106552  0.096511  ...   \n",
       "...                        ...       ...       ...       ...       ...  ...   \n",
       "NRV                  -0.014279 -0.065262 -0.001528 -0.099809 -0.018441  ...   \n",
       "UTT                  -0.000219 -0.083139  0.033362 -0.119045  0.125617  ...   \n",
       "MMU                  -0.025217 -0.026836 -0.026815 -0.198236  0.021817  ...   \n",
       "houghton             -0.019786  0.072973 -0.017989 -0.196128  0.026056  ...   \n",
       "universityofredlands -0.046135  0.017856 -0.078710 -0.128699  0.092061  ...   \n",
       "\n",
       "                           141       142       143       144       145  \\\n",
       "subreddit                                                                \n",
       "SquaredCircle        -0.061495 -0.183028 -0.099551  0.031485 -0.040188   \n",
       "AskReddit            -0.039066 -0.043172 -0.106157  0.105634 -0.045787   \n",
       "politics              0.034073 -0.087685 -0.129094  0.110916  0.047369   \n",
       "memes                 0.024190 -0.042757 -0.033878  0.041545 -0.001212   \n",
       "teenagers             0.013686 -0.014345 -0.004146  0.055941 -0.009106   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "NRV                  -0.054521 -0.062958 -0.112747  0.098669 -0.049754   \n",
       "UTT                  -0.019219 -0.092823 -0.096780  0.095344 -0.114785   \n",
       "MMU                  -0.075906 -0.067976 -0.035603 -0.009426 -0.084691   \n",
       "houghton             -0.004768 -0.076079 -0.103230  0.060556 -0.111134   \n",
       "universityofredlands -0.024964 -0.054390 -0.168895  0.087481 -0.119883   \n",
       "\n",
       "                           146       147       148       149       150  \n",
       "subreddit                                                               \n",
       "SquaredCircle         0.143292  0.040536 -0.008464  0.041863 -0.172806  \n",
       "AskReddit             0.063289  0.057239 -0.198356  0.061649 -0.023330  \n",
       "politics              0.014214  0.025798 -0.121198  0.155587 -0.057969  \n",
       "memes                 0.076116  0.036539 -0.102034  0.054330 -0.073219  \n",
       "teenagers             0.085962  0.030374 -0.028468  0.069988 -0.039540  \n",
       "...                        ...       ...       ...       ...       ...  \n",
       "NRV                  -0.015509  0.117170 -0.216936  0.008118 -0.123790  \n",
       "UTT                   0.023995  0.075017 -0.151421  0.048709 -0.065192  \n",
       "MMU                   0.068536 -0.040373 -0.134642  0.068508 -0.132696  \n",
       "houghton              0.028949 -0.011122 -0.188779  0.003880 -0.115659  \n",
       "universityofredlands  0.006224  0.023883 -0.181816  0.064438 -0.048578  \n",
       "\n",
       "[10541 rows x 150 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_FRAME = \"biweekly\"\n",
    "embedding = load_embedding(\"/h/224/cameron/Political-Subreddit-Embedding/trained_embeddings/vecs_0.0028_15.0.txt\",split=False)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(sub_a,sub_ap,sub_b,embedding,return_score=False):\n",
    "    \"\"\"\n",
    "        sub_a is to sub_ap, as sub_b is to ??\n",
    "        sub_ap + sub_b - sub_a\n",
    "        returns the subreddit that best answers the analogy\n",
    "    \"\"\"\n",
    "    assert sub_a in embedding.index.values, \"{} is not in the dataset\".format(sub_a)\n",
    "    assert sub_ap in embedding.index.values, \"{} is not in the dataset\".format(sub_ap)\n",
    "    assert sub_b in embedding.index.values, \"{} is not in the dataset\".format(sub_b)\n",
    "    vec_a = embedding.loc[sub_a].to_numpy().flatten()\n",
    "    vec_ap = embedding.loc[sub_ap].to_numpy().flatten()\n",
    "    vec_b = embedding.loc[sub_b].to_numpy().flatten()\n",
    "    vec_bp = vec_ap + (vec_b - vec_a)\n",
    "    all_other_vecs = embedding[~embedding.index.isin([sub_a,sub_ap,sub_b])]\n",
    "    similarity = np.apply_along_axis(lambda x : cos_sim(x,vec_bp), 1, all_other_vecs)\n",
    "    winner_ind = similarity.argmax()\n",
    "    if return_score:\n",
    "        return all_other_vecs.index.values[winner_ind], similarity[winner_ind]\n",
    "    return all_other_vecs.index.values[winner_ind]\n",
    "\n",
    "# a = \"socialism\"\n",
    "# ap = \"Libertarian\"\n",
    "# b = \"EnoughCommieSpam\"\n",
    "# print(\"r/{} is to r/{} as r/{} is to r/{}\".format(a,ap,b,analogy(a,ap,b,embedding)))\n",
    "# # a = \"SandersForPresident\"\n",
    "# ap = \"ElizabethWarren\"\n",
    "# b = \"BaemyKlobaechar\"\n",
    "# print(\"r/{} is to r/{} as r/{} is to r/{}\".format(a,ap,b,analogy(a,ap,b,embedding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/224/cameron/miniconda3/envs/pyspark_env/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1865624b5edc49718194d57025815ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           subreddit_from           subreddit_to  similarity\n",
      "1         LeftWithoutEdge     centerleftpolitics    0.787030\n",
      "2   EnoughLibertarianSpam     centerleftpolitics    0.767105\n",
      "3                JoeBiden     centerleftpolitics    0.763642\n",
      "4     PoliticalDiscussion                tuesday    0.761433\n",
      "5             neutralnews        NeutralPolitics    0.759140\n",
      "6            Ask_Politics                tuesday    0.756986\n",
      "7             AskALiberal                tuesday    0.754963\n",
      "8                  Kamala     centerleftpolitics    0.753671\n",
      "9       TempleBelmontLive            ABCsportsTV    0.753510\n",
      "10       moderatepolitics                tuesday    0.749236\n",
      "11                   ABDL            ABCsportsTV    0.747786\n",
      "12              60fpsporn            ABCsportsTV    0.747616\n",
      "13      TheMajorityReport     centerleftpolitics    0.747255\n",
      "14        NeutralPolitics                tuesday    0.747113\n",
      "15                ACTrade            ABCsportsTV    0.746913\n",
      "16               Acadiana            ABCsportsTV    0.745298\n",
      "17                6ix9ine            ABCsportsTV    0.744385\n",
      "18                34Honor            ABCsportsTV    0.744209\n",
      "19                  18_19            ABCsportsTV    0.743820\n",
      "20  CALVAREZvsJACOBSLivee            ABCsportsTV    0.743771\n",
      "21                    4x4            ABCsportsTV    0.743239\n",
      "22             ModelUSGov           ModelUSHouse    0.741619\n",
      "23              AbyssRium                    4x4    0.740686\n",
      "24           Marianne2020     centerleftpolitics    0.737880\n",
      "25  WarriorsBlazersLiveHD            ABCsportsTV    0.737286\n",
      "26  LiverpoolvsBarcaLivee        Netsvs76ersLive    0.737159\n",
      "27                  egham  LiverpoolvsBarcaLivee    0.736675\n",
      "28                bundary            ABCsportsTV    0.736285\n",
      "29  u_BusinessEntertainer      UFC236LIVEStreams    0.735367\n",
      "30               LabourUK                 LibDem    0.734775\n",
      "31          Stream_Boxing  TottenhamvsAjaxLiveHD    0.734644\n",
      "32   CanelovsJacobsLiveHq        Netsvs76ersLive    0.734488\n",
      "33                 gundda            ABCsportsTV    0.734363\n",
      "34   Political_Revolution               VoteBlue    0.734276\n",
      "35           NFL2019Draft        Netsvs76ersLive    0.734031\n",
      "36       ShitWehraboosSay           DerScheisser    0.733792\n",
      "37         redditSPORTStv            ABCsportsTV    0.733373\n",
      "38   CHAMPIONSLEAGUELiveT            ABCsportsTV    0.732852\n",
      "39           demsocialist     centerleftpolitics    0.731971\n",
      "40        CredibleDefense             WarCollege    0.731841\n",
      "41  PresidentialRaceMemes     centerleftpolitics    0.731533\n",
      "42  TottenhamvsAjaxLiveHD            ABCsportsTV    0.731162\n",
      "43  BarcelonavsRMadridLiv  LiverpoolvsBarcaLivee    0.730474\n",
      "44              fubohdweb  LiverpoolvsBarcaLivee    0.730152\n",
      "45    PurdueTennesseeLive  LiverpoolvsBarcaLivee    0.729760\n",
      "46         slatestarcodex               TheMotte    0.729693\n",
      "47                 ASRoma            ABCsportsTV    0.728948\n",
      "48           WayOfTheBern     centerleftpolitics    0.727921\n",
      "49       CrawfordKhanLive            ABCsportsTV    0.726004\n",
      "50             POTUSWatch                tuesday    0.725484\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def get_possible_fits(a,ap,embedding,k=20):\n",
    "    \"\"\"\n",
    "        Returns possible b and bp's for an analogy starting with a and ap\n",
    "        Iterate through each vector in the embedding, have that act as the b and find bp.\n",
    "        Sort through ones that match the best and return top k.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Find subreddits that are relatively close to the base \"a\" subreddit, and take the top 5% percentile of subreddits in terms of \n",
    "    # closeness ot that base\n",
    "    possible_fits = embedding.copy().apply(lambda x : cos_sim(np.array(x),embedding.loc[a]),axis=1,result_type=\"expand\").sort_values(0,ascending=False).head(len(embedding)//20)\n",
    "    possible_fits = possible_fits.reset_index().set_index(\"subreddit\")\n",
    "    # Search for best possible fits in ENTIRE embedding, but only use somewhat close starting points\n",
    "    possible_fits[[\"subreddit_to\",\"similarity\"]] = possible_fits.progress_apply(lambda x : analogy(a,ap,x.name,embedding,True),axis=1,result_type=\"expand\")\n",
    "    possible_fits = possible_fits[[\"subreddit_to\",\"similarity\"]].sort_values(\"similarity\",ascending=False).reset_index()\n",
    "    possible_fits = possible_fits[~possible_fits[\"subreddit\"].isin([a,ap])]\n",
    "    possible_fits = possible_fits.rename({\"subreddit\":\"subreddit_from\"},axis=1)\n",
    "    return  possible_fits.head(k)\n",
    "\n",
    "a = \"chomsky\"\n",
    "ap = \"neoliberal\"\n",
    "# # p1 = get_possible_fits(a,ap,embedding,k=20)\n",
    "# # print(p1)\n",
    "# a = \"SandersForPresident\"\n",
    "# ap = \"The_Donald\"\n",
    "# a = \"nba\"\n",
    "# ap = \"nfl\"\n",
    "p2 = get_possible_fits(a,ap,embedding,k=50)\n",
    "print(\"{} is to {} best analogy endings\".format(a,ap))\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91244670cdf4dc0a88346698eae55d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Out of 18 analogies, 13 were predicted correctly (72.22222222222221%)\n",
      "oakland is to oaklandraiders as kansascity is to KansasCityChiefs (predicted as: miamidolphins)\n",
      "oakland is to oaklandraiders as sanfrancisco is to 49ers (predicted as: miamidolphins)\n",
      "SaltLakeCity is to UtahJazz as boston is to bostonceltics (predicted as: redsox)\n",
      "SaltLakeCity is to UtahJazz as Miami is to heat (predicted as: GoNets)\n",
      "StLouis is to stlouisblues as TwinCities is to wildhockey (predicted as: Minneapolis)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def predict_analogies(analogy_names,embedding,frac=0.5,show_prog=True):\n",
    "    fp = \"/h/224/cameron/Political-Subreddit-Embedding/external_datasets/validation/{}.csv\"\n",
    "    data_frames = [pd.read_csv(fp.format(name)).sample(frac=frac) for name in analogy_names]\n",
    "    pairs = []\n",
    "    for analogy_df in data_frames:\n",
    "        tuples = [tuple(x) for x in analogy_df.to_numpy()]\n",
    "        analogy_pairs = list(combinations(tuples,2))\n",
    "        pairs += analogy_pairs\n",
    "    pred = []\n",
    "    actual = []\n",
    "    tups = []\n",
    "    p = tqdm(pairs) if show_prog else pairs\n",
    "    for (a,ap),(b,bp) in p:\n",
    "        try: \n",
    "            p = analogy(a.strip(),ap.strip(),b.strip(),embedding)\n",
    "            pred.append(p)\n",
    "            actual.append(bp)\n",
    "            tups.append(((a,ap),(b,bp)))\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(pred),np.array(actual), tups\n",
    "\n",
    "def score(pred,actual):\n",
    "    return (pred == actual).mean() * 100, (pred == actual).sum()\n",
    "\n",
    "data_sets = [\"football\",\"basketball\",\"baseball\",\"hockey\",\"populous_cities\"]\n",
    "# data_sets = [\"populous_cities\"]\n",
    "\n",
    "pred, actual, tuples = predict_analogies(data_sets,embedding,frac=0.1)\n",
    "accuracy, num_correct = score(pred,actual)\n",
    "print(\"Out of {} analogies, {} were predicted correctly ({}%)\".format(len(pred),num_correct,accuracy))\n",
    "for p,act,((a,ap),(b,_)) in zip(pred,actual,tuples):\n",
    "    if not p==act: print(\"{} is to {} as {} is to {} (predicted as: {})\".format(a,ap,b,act,p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Embedding projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_dir = \"/h/224/cameron/public_html\"\n",
    "\n",
    "name = \"Reddit-2019_0.001_39\"\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(pub_dir, 'metadata.tsv'), \"w\") as f:\n",
    "    for sub in embedding.index:\n",
    "        f.write(\"{}\\n\".format(sub))\n",
    "\n",
    "embedding.to_csv(os.path.join(pub_dir, 'vecs.tsv'),      \n",
    "        sep='\\t',\n",
    "        index=False,\n",
    "        header=False,\n",
    "        encoding='utf-8')\n",
    "\n",
    "config = {\n",
    "      \"tensorName\": name,\n",
    "      \"tensorShape\": [\n",
    "        vecs.shape[0],\n",
    "        vecs.shape[1]\n",
    "      ],\n",
    "      \"tensorPath\": os.path.join(pub_dir, 'metadata.tsv'),\n",
    "      \"metadataPath\": os.path.join(pub_dir, 'vecs.tsv')\n",
    "    }\n",
    "\n",
    "with open(os.path.join(pub_dir, name+\"_config.json\"), \"w+\") as text_file:\n",
    "    text_file.write(json.dumps({\"embeddings\": [config]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
